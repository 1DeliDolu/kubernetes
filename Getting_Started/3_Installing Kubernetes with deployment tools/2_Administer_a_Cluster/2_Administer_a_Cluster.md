# 2 Administer a Cluster

## üöÄ Overprovision Node Capacity For A Cluster / √úberprovisionierung der Node-Kapazit√§t f√ºr einen Cluster


**Deutsche √úbersetzung:**  
Diese Anleitung beschreibt, wie Sie in Ihrem Kubernetes-Cluster die **√úberprovisionierung von Nodes** konfigurieren.  
Node-√úberprovisionierung ist eine Strategie, bei der **ein Teil der Clusterressourcen proaktiv reserviert** wird.  
Diese Reservierung reduziert die Zeit, die zum Planen neuer Pods bei Skalierungsereignissen ben√∂tigt wird, und verbessert die **Reaktionsf√§higkeit des Clusters** auf pl√∂tzliche Lastspitzen.

Durch das Beibehalten einer gewissen ungenutzten Kapazit√§t stellen Sie sicher, dass Ressourcen sofort verf√ºgbar sind, wenn neue Pods erstellt werden ‚Äî so vermeiden Sie, dass Pods in den Zustand *Pending* √ºbergehen, w√§hrend der Cluster hochskaliert.

---

## üß© Before you begin / Bevor Sie beginnen

- Sie ben√∂tigen einen **laufenden Kubernetes-Cluster**.  
- Das Kommandozeilentool `kubectl` muss korrekt mit Ihrem Cluster verbunden sein.  
- Grundkenntnisse √ºber **Deployments**, **Pod-Priorit√§ten** und **PriorityClasses** sind erforderlich.  
- Ihr Cluster sollte √ºber einen **Autoscaler** verf√ºgen, der Nodes je nach Last verwaltet.

---

## üß© Create a PriorityClass / Eine PriorityClass erstellen

Definieren Sie zun√§chst eine **PriorityClass** f√ºr die Platzhalter-Pods.  
Diese Pods werden mit einer **negativen Priorit√§t** versehen, damit sie bei Ressourcenknappheit als erste verdr√§ngt werden k√∂nnen.

Datei: `priorityclass/low-priority-class.yaml`

```yaml
apiVersion: scheduling.k8s.io/v1
kind: PriorityClass
metadata:
  name: placeholder # diese Pods repr√§sentieren Platzhalterkapazit√§t
value: -1000
globalDefault: false
description: "Negative Priorit√§t f√ºr Platzhalter-Pods zur Aktivierung der √úberprovisionierung."
````

Erstellen Sie die PriorityClass:

```bash
kubectl apply -f https://k8s.io/examples/priorityclass/low-priority-class.yaml
```

Diese PriorityClass wird sp√§ter im Deployment verwendet, das die Platzhalter-Pods ausf√ºhrt.

---

## üß© Run Pods that request node capacity / Platzhalter-Pods bereitstellen

Beispielmanifest: `deployments/deployment-with-capacity-reservation.yaml`

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: capacity-reservation
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: capacity-placeholder
  template:
    metadata:
      labels:
        app.kubernetes.io/name: capacity-placeholder
      annotations:
        kubernetes.io/description: "Kapazit√§tsreservierung"
    spec:
      priorityClassName: placeholder
      affinity: # Versucht, Pods auf unterschiedliche Nodes zu verteilen
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchLabels:
                  app.kubernetes.io/name: capacity-placeholder
              topologyKey: topology.kubernetes.io/hostname
      containers:
      - name: pause
        image: registry.k8s.io/pause:3.6
        resources:
          requests:
            cpu: "50m"
            memory: "512Mi"
          limits:
            memory: "512Mi"
```

---

## üß© Pick a namespace / Namespace f√ºr Platzhalter-Pods w√§hlen

Erstellen oder w√§hlen Sie einen **Namespace**, in dem die Platzhalter-Pods laufen sollen.

---

## üß© Create the placeholder Deployment / Platzhalter-Deployment erstellen

Erstellen Sie das Deployment auf Basis des obigen Manifests:

```bash
# √Ñndern Sie den Namespace "example" in Ihren gew√ºnschten Namespace
kubectl --namespace example apply -f https://k8s.io/examples/deployments/deployment-with-capacity-reservation.yaml
```

---

## üß© Adjust placeholder resource requests / Ressourcenanfragen anpassen

Definieren Sie √ºber die Ressourcensektion, wie viel CPU und Speicher Sie **√ºberprovisionieren** m√∂chten.
Diese Werte bestimmen, wie viel Kapazit√§t im Cluster reserviert bleibt.

Sie k√∂nnen die Datei lokal herunterladen und anpassen oder direkt mit `kubectl` bearbeiten:

```bash
kubectl edit deployment capacity-reservation
```

Beispiel:
Um insgesamt **0,5 CPU** und **1 GiB Speicher** √ºber 5 Platzhalter-Pods zu reservieren, definieren Sie pro Pod:

```yaml
resources:
  requests:
    cpu: "100m"
    memory: "200Mi"
  limits:
    cpu: "100m"
```

---

## üß© Set the desired replica count / Replikazahl festlegen

Berechnen Sie die reservierte Gesamtkapazit√§t:

* **CPU gesamt:** 5 √ó 0.1 = 0.5 CPU (500 m)
* **Speicher gesamt:** 5 √ó 200 Mi = 1 GiB

Skalieren Sie das Deployment:

```bash
kubectl scale deployment capacity-reservation --replicas=5
```

√úberpr√ºfen Sie das Ergebnis:

```bash
kubectl get deployment capacity-reservation
```

Beispielausgabe:

```
NAME                   READY   UP-TO-DATE   AVAILABLE   AGE
capacity-reservation   5/5     5            5           2m
```

> **Hinweis:**
> Einige Autoscaler (z. B. **Karpenter**) behandeln *preferred* Affinit√§tsregeln als *harte* Regeln.
> Wenn Sie einen solchen Autoscaler verwenden, bestimmt die eingestellte Replikazahl auch die **Mindestanzahl an Nodes** im Cluster.

---

## üß© What's next / N√§chste Schritte

* Lernen Sie mehr √ºber [PriorityClasses](https://kubernetes.io/docs/concepts/scheduling-eviction/pod-priority-preemption/) und deren Einfluss auf die Pod-Planung.
* Erkunden Sie [Node Autoscaling](https://kubernetes.io/docs/tasks/administer-cluster/cluster-management/#scaling-your-cluster), um Ihre Clustergr√∂√üe dynamisch an die Arbeitslast anzupassen.
* Verstehen Sie das Konzept der [Pod Preemption](https://kubernetes.io/docs/concepts/scheduling-eviction/pod-priority-preemption/), das Kubernetes verwendet, um Ressourcenengp√§sse zu bew√§ltigen.


