## ğŸš€ Container Runtimes / Container-Laufzeitumgebungen


**Deutsche Ãœbersetzung:**  
> **Hinweis:**  
> Seit **Kubernetes Version 1.24** wurde **Dockershim** aus dem Projekt entfernt. Lies die **[Dockershim Removal FAQ](https://kubernetes.io/docs/news/2022/02/17/dockershim-faq/)** fÃ¼r weitere Informationen.

Du musst auf jedem **Node** im Cluster eine **Container-Laufzeitumgebung (Runtime)** installieren, damit **Pods** dort ausgefÃ¼hrt werden kÃ¶nnen.  
Diese Seite beschreibt die grundlegenden Anforderungen und Aufgaben zur Einrichtung von Nodes.

**Kubernetes 1.34** erfordert eine Laufzeitumgebung, die der **Container Runtime Interface (CRI)**-Spezifikation entspricht.  
Siehe **[CRI-Version-KompatibilitÃ¤t](https://kubernetes.io/docs/concepts/architecture/cri/)** fÃ¼r weitere Details.

Diese Seite zeigt, wie mehrere gÃ¤ngige Container-Runtimes mit Kubernetes verwendet werden kÃ¶nnen:

- `containerd`  
- `CRI-O`  
- `Docker Engine`  
- `Mirantis Container Runtime`

> **Hinweis:**  
> FrÃ¼here Kubernetes-Versionen (vor v1.24) beinhalteten eine direkte Integration mit der **Docker Engine** Ã¼ber eine Komponente namens **dockershim**.  
> Diese spezielle Integration ist nun entfernt (die Entfernung wurde mit Version 1.20 angekÃ¼ndigt).  
> Siehe **[PrÃ¼fen, ob dich die Dockershim-Entfernung betrifft](https://kubernetes.io/blog/2020/12/02/dockershim-faq/)** und **[Migration von Dockershim](https://kubernetes.io/docs/tasks/administer-cluster/migrating-from-dockershim/)** fÃ¼r weitere Details.

Wenn du eine andere Version von Kubernetes als **v1.34** verwendest, Ã¼berprÃ¼fe bitte die Dokumentation zu deiner jeweiligen Version.


---

## âš™ï¸ Install and configure prerequisites / Voraussetzungen installieren und konfigurieren


### ğŸŒ Network configuration / Netzwerkkonfiguration

StandardmÃ¤ÃŸig erlaubt der Linux-Kernel nicht, dass **IPv4-Pakete** zwischen Schnittstellen weitergeleitet werden.  
Die meisten Kubernetes-Netzwerkimplementierungen Ã¤ndern diese Einstellung automatisch, einige erwarten jedoch, dass der Administrator sie manuell setzt.  
(Weitere sysctl-Parameter, Kernel-Module oder spezifische Anforderungen kÃ¶nnen je nach Netzwerk-Plugin notwendig sein.)

#### IPv4-Paketweiterleitung aktivieren

FÃ¼hre Folgendes aus, um die IPv4-Weiterleitung manuell zu aktivieren:

```bash
# sysctl-Parameter fÃ¼r Setup, bleiben nach Neustart erhalten
cat <<EOF | sudo tee /etc/sysctl.d/k8s.conf
net.ipv4.ip_forward = 1
EOF

# sysctl-Parameter anwenden, ohne Neustart
sudo sysctl --system
````

ÃœberprÃ¼fe anschlieÃŸend, ob der Wert gesetzt wurde:

```bash
sysctl net.ipv4.ip_forward
```

---

## ğŸ§© cgroup drivers / Cgroup-Treiber

**Deutsche Ãœbersetzung:**
Unter Linux werden **Control Groups (cgroups)** verwendet, um Ressourcen zu verwalten, die Prozessen zugewiesen werden.
Sowohl der **kubelet** als auch die zugrunde liegende Container-Laufzeit mÃ¼ssen mit cgroups interagieren, um Ressourcenlimits (z. B. CPU/RAM) durchzusetzen.
Dazu mÃ¼ssen beide denselben **cgroup driver** verwenden â€“ andernfalls kommt es zu InstabilitÃ¤ten.

Es gibt zwei verfÃ¼gbare Treiber:

* `cgroupfs`
* `systemd`

### ğŸ§± cgroupfs driver

Der `cgroupfs`-Treiber ist der Standardtreiber des **kubelet**.
Dabei interagieren `kubelet` und Runtime direkt mit dem cgroup-Dateisystem.
Dieser Treiber **wird nicht empfohlen**, wenn `systemd` als Init-System verwendet wird, da `systemd` einen eigenen cgroup-Manager bereitstellt.
Bei Verwendung von **cgroup v2** sollte **systemd** als Treiber verwendet werden.

### âš™ï¸ systemd cgroup driver

Wenn `systemd` das Init-System ist, verwaltet es selbst die Root-cgroup.
In diesem Fall fÃ¼hrt die parallele Nutzung von `cgroupfs` zu **zwei verschiedenen cgroup-Managern**, was zu widersprÃ¼chlichen Ressourcensichten und potenzieller InstabilitÃ¤t fÃ¼hren kann.

Die empfohlene LÃ¶sung ist daher, `systemd` als **cgroup driver** fÃ¼r sowohl den **kubelet** als auch die **Container Runtime** zu konfigurieren.

Beispielkonfiguration in `KubeletConfiguration`:

```yaml
apiVersion: kubelet.config.k8s.io/v1beta1
kind: KubeletConfiguration
...
cgroupDriver: systemd
```

> **Hinweis:**
> Seit **Kubernetes v1.22** setzt `kubeadm` standardmÃ¤ÃŸig `systemd` als cgroupDriver, wenn der Benutzer keinen Wert angibt.
> Wird `systemd` fÃ¼r den kubelet verwendet, muss es **auch fÃ¼r die Container Runtime** gesetzt werden.
> Siehe die Dokumentation der jeweiligen Runtime (z. B. [containerd](https://containerd.io/) oder [CRI-O](https://cri-o.io/)).

Ab **Kubernetes 1.34** kann kubelet bei aktivem **Feature Gate `KubeletCgroupDriverFromCRI`** automatisch den passenden Treiber von der Runtime erkennen.
Ã„ltere Runtimes (z. B. `containerd 1.x`) unterstÃ¼tzen diese Funktion nicht, wodurch kubelet auf den konfigurierten Wert zurÃ¼ckfÃ¤llt.

> âš ï¸ **Achtung:**
> Das Ã„ndern des cgroup-Treibers auf einem laufenden Node ist heikel.
> Bereits erstellte Pods kÃ¶nnen danach fehlschlagen. In der Regel sollte der Node ersetzt oder neu provisioniert werden.

---

## ğŸ”„ Migrating to the systemd driver / Migration auf den systemd-Treiber

**Deutsche Ãœbersetzung:**
Wenn du in einem bestehenden, durch `kubeadm` verwalteten Cluster auf den `systemd`-Treiber umsteigen mÃ¶chtest, folge der Anleitung unter
**[Konfiguration des cgroup-Treibers](https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/configure-cgroup-driver/)**.

---

## ğŸ§© CRI version support / UnterstÃ¼tzung von CRI-Versionen

**Deutsche Ãœbersetzung:**
Deine Container-Laufzeitumgebung muss mindestens die **v1alpha2**-Version des **Container Runtime Interface (CRI)** unterstÃ¼tzen.
Ab **Kubernetes v1.26** wird ausschlieÃŸlich die **v1-API** unterstÃ¼tzt.
Wenn eine Runtime die v1-API nicht implementiert, fÃ¤llt kubelet (in Ã¤lteren Versionen) auf die **veraltete v1alpha2-API** zurÃ¼ck.

---

## ğŸ³ Container runtimes / Container-Laufzeitumgebungen

> **Hinweis:**
> Die folgenden Abschnitte verweisen auf Drittanbieterprojekte, die von Kubernetes genutzt werden.
> Das Kubernetes-Projekt Ã¼bernimmt keine Verantwortung fÃ¼r deren Wartung oder FunktionalitÃ¤t.
> Weitere Informationen findest du in den **[CNCF-Richtlinien](https://www.cncf.io/)**.

### containerd

Schritte zur Nutzung von **containerd** als CRI-Runtime:

* Folge den Anweisungen unter [Getting started with containerd](https://github.com/containerd/containerd/blob/main/docs/getting-started.md).
* Konfiguriere `/etc/containerd/config.toml`.

  * Standard-Socket unter Linux: `/run/containerd/containerd.sock`
  * Standard-Socket unter Windows: `npipe://./pipe/containerd-containerd`

**systemd cgroup driver aktivieren:**

Containerd 1.x:

```toml
[plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc.options]
  SystemdCgroup = true
```

Containerd 2.x:

```toml
[plugins.'io.containerd.cri.v1.runtime'.containerd.runtimes.runc.options]
  SystemdCgroup = true
```

> **Hinweis:**
> Wenn `containerd` aus einem Paket installiert wurde, kann das CRI-Plugin standardmÃ¤ÃŸig deaktiviert sein.
> Stelle sicher, dass `cri` **nicht** in `disabled_plugins` steht.
> Nach Ã„nderungen:
>
> ```bash
> sudo systemctl restart containerd
> ```

**Sandbox-Image anpassen:**

```toml
[plugins."io.containerd.grpc.v1.cri"]
  sandbox_image = "registry.k8s.io/pause:3.10"
```

---

### CRI-O

Installation gemÃ¤ÃŸ **[CRI-O Install Instructions](https://github.com/cri-o/cri-o/blob/main/install.md)**.

StandardmÃ¤ÃŸig verwendet CRI-O den **systemd**-Treiber.
Zum Wechsel auf `cgroupfs`:

```toml
[crio.runtime]
conmon_cgroup = "pod"
cgroup_manager = "cgroupfs"
```

Der Standard-CRI-Socket lautet:

```
/var/run/crio/crio.sock
```

**Sandbox-Image anpassen:**

```toml
[crio.image]
pause_image="registry.k8s.io/pause:3.10"
```

KonfigurationsÃ¤nderung aktivieren mit:

```bash
systemctl reload crio
```

---

### Docker Engine

> **Hinweis:**
> Diese Anleitung setzt voraus, dass du den **cri-dockerd** Adapter verwendest.

* Installiere Docker entsprechend deiner Distribution.
* Installiere `cri-dockerd` laut Dokumentation.
* Standard-CRI-Socket: `/run/cri-dockerd.sock`

**Pause-Image anpassen (Ã¼ber CLI-Argument):**

```
--pod-infra-container-image=registry.k8s.io/pause:3.10
```

---

### Mirantis Container Runtime (MCR)

Ehemals **Docker Enterprise Edition**.
Kann mit Kubernetes Ã¼ber **cri-dockerd** verwendet werden (wird mit MCR ausgeliefert).
Installationsanleitung: [MCR Deployment Guide](https://docs.mirantis.com/).

**CRI-Socket prÃ¼fen:**

```
systemctl status cri-docker.socket
```

---

## ğŸš€ What's next / Wie geht es weiter

**Deutsche Ãœbersetzung:**
ZusÃ¤tzlich zur Container-Laufzeit benÃ¶tigt dein Cluster ein funktionierendes **Netzwerk-Plugin**.
Einige Inhalte auf dieser Seite verweisen auf Drittanbieterprojekte, fÃ¼r die die Kubernetes-Autoren **nicht verantwortlich** sind.
Siehe die **[CNCF-Webseitenrichtlinien](https://www.cncf.io/)** fÃ¼r weitere Informationen.
Lies die **Content-Richtlinien**, bevor du Ã„nderungen oder neue externe Links vorschlÃ¤gst.


